ID,Function,Subcategory,Question,Response Type,Option 1,Option 2,Option 3,Weight
GOV-1.1,GOVERN,GOVERN 1.1: The organization establishes and communicates its AI risk management policies and procedures.,Does your organization have a documented policy or procedure specifically for managing risks associated with AI systems?,Yes/No,"Yes, we have a formal policy.","No, we do not.",We are in the process of developing one.,3
GOV-1.2,GOVERN,GOVERN 1.1: The organization establishes and communicates its AI risk management policies and procedures.,Are these AI risk management policies communicated to all relevant employees and stakeholders?,Yes/No,"Yes, widely communicated.","No, not yet.",Only to a small group.,2
GOV-2.1,GOVERN,GOVERN 2.1: The organization defines roles and responsibilities for AI risk management.,Are specific roles and responsibilities for AI risk management formally defined and assigned?,Yes/No,"Yes, all roles are defined.","No, they are not.",Only for a few select roles.,3
GOV-2.2,GOVERN,GOVERN 2.1: The organization defines roles and responsibilities for AI risk management.,"Does your organization have a cross-functional committee (e.g., AI ethics committee) to oversee AI risks?",Yes/No,"Yes, we have a dedicated committee.","No, we do not.",It is managed by a single department.,2
GOV-3.1,GOVERN,GOVERN 3.1: The organization integrates AI risk management into its broader enterprise risk management framework.,Is AI risk management integrated into your company's broader enterprise risk management (ERM) framework?,Yes/No,"Yes, it is fully integrated.","No, it is a standalone process.",We don't have an ERM framework.,3
GOV-3.2,GOVERN,GOVERN 3.1: The organization integrates AI risk management into its broader enterprise risk management framework.,"Are AI risks considered in the same manner as financial, operational, or cybersecurity risks?",Yes/No,"Yes, with equal priority.","No, they are considered separately.",They are a low priority.,2
MAP-1.1,MAP,MAP 1.1: The organization identifies and characterizes AI systems and their components.,Does your organization maintain a complete inventory of all AI systems currently in use?,Yes/No,"Yes, we have a complete inventory.","No, we don't.",Only for a few key systems.,3
MAP-1.2,MAP,MAP 1.1: The organization identifies and characterizes AI systems and their components.,"Does your inventory include details such as the model, data sources, and intended use of each AI system?",Yes/No,"Yes, all details are captured.","No, the inventory is very basic.",We are working on it.,2
MAP-2.1,MAP,MAP 2.1: The organization identifies potential risks and benefits.,"Has your organization conducted a formal assessment to identify potential risks (e.g., bias, privacy) associated with your AI systems?",Yes/No,"Yes, we have a formal process.","No, we have not.",Only on an ad-hoc basis.,3
MAP-2.2,MAP,MAP 2.1: The organization identifies potential risks and benefits.,Do you consider the potential positive and negative societal impacts of your AI systems during development?,Yes/No,"Yes, it is a key part of our process.","No, we do not.",Only when required by regulation.,2
MEA-1.1,MEASURE,"MEASURE 1.1: The organization measures and evaluates AI system performance, trustworthiness, and risk.",Do you have a process to continuously monitor the performance of your deployed AI models?,Yes/No,"Yes, we have continuous monitoring.","No, we do not.",Only when there's an issue.,3
MEA-1.2,MEASURE,"MEASURE 1.1: The organization measures and evaluates AI system performance, trustworthiness, and risk.","Do you have defined metrics to measure for fairness, bias, and accuracy for your AI systems?",Yes/No,"Yes, we track these metrics.","No, we do not.",Only for some systems.,3
MEA-2.1,MEASURE,MEASURE 2.1: The organization identifies and documents AI-specific data vulnerabilities and security risks.,Are AI systems and their data pipelines regularly assessed for security vulnerabilities?,Yes/No,"Yes, with regular assessments.","No, this is not a priority.",Only during initial development.,3
MEA-2.2,MEASURE,MEASURE 2.1: The organization identifies and documents AI-specific data vulnerabilities and security risks.,Do you conduct regular privacy impact assessments for AI systems that handle sensitive data?,Yes/No,"Yes, we have a formal process.","No, we do not.",Only if it's a new system.,2
MAN-1.1,MANAGE,MANAGE 1.1: The organization implements risk mitigation measures.,"Are risk mitigation strategies, such as a human-in-the-loop, implemented for high-risk AI systems?",Yes/No,"Yes, we use risk-based controls.","No, we do not.",Only on an ad-hoc basis.,3
MAN-1.2,MANAGE,MANAGE 1.1: The organization implements risk mitigation measures.,Do you have a clear plan for how to handle a failure or a negative outcome from an AI system?,Yes/No,"Yes, we have a response plan.","No, we do not.",We handle it on a case-by-case basis.,2
MAN-2.1,MANAGE,MANAGE 2.1: The organization engages in continuous monitoring and improvement of its AI systems.,Do you have a process to regularly review and update your AI risk management policies?,Yes/No,"Yes, we review annually.","No, they are static.",Only when a major change occurs.,2
MAN-2.2,MANAGE,MANAGE 2.1: The organization engages in continuous monitoring and improvement of its AI systems.,Do you have a process for collecting feedback from users and stakeholders to identify new or emerging risks?,Yes/No,"Yes, we have a formal feedback loop.","No, we do not.",We only collect internal feedback.,1